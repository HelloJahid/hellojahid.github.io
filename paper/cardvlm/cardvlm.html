<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CarDVLM">
  <meta name="keywords" content="GPT-4, open-source, vision-language">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CarDVLM</title>


  <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <!-- <link rel="icon" href="./static/images/icon.png"> -->
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="shortcut icon" href="path/to/favicon.ico" type="image/x-icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  </head>

  <style>

    #main{
        position: relative;;
        width: 1200px;
    }

    .box{
        float: left;
        padding: 15px 0 0 15px;
/*        background-color: red;*/
    }

    .pic{
        width: 500px;
        padding: 10px;
        border: 1px solid #ccc;
        border-radius: 5px;
        background-color: #fff;
    }

    .pic img{
        width: 500px;
    }

  </style>



  <body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CarDVLM:</h1>
          <h2 class="title is-2 publication-title">Car Damage Assessment using Vision LLM</h2>
          <div class="is-size-5">
            <span class="author-block">
                <a href="https://hellojahid.github.io/" style="color:#008AD7;font-weight:normal;">Md Jahid Hasan<sup>*</sup>
                </a>,                
            </span>
            <!-- <span class="author-block">
              <a href="https://junchen14.github.io/" style="color:#008AD7;font-weight:normal;">Jun Chen<sup>*</sup></a>,</span>
            <span class="author-block">
              <a href="https://xiaoqian-shen.github.io/" style="color:#008AD7;font-weight:normal;">Xiaoqian Shen</a>,
            </span>
            <span class="author-block">
              <a href="https://lx709.github.io/" style="color:#008AD7;font-weight:normal;">Xiang Li</a>,
            </span>
            <span class="author-block">
              <a href="https://www.mohamed-elhoseiny.com/" style="color:#008AD7;font-weight:normal;">Mohamed Elhoseiny</a>
            </span> -->
            
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> RMIT University </span>
            <!-- <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b>UCLA; </span> -->
            <!-- <span class="author-block"><b style="color:#00A4EF; font-weight:normal">&#x25B6 </b>Microsoft Research, Redmond; </span> -->
            <!-- <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b>Microsoft Cloud & AI </span> -->
          </div>

          
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#" target="_blank"
                   class="external-link button is-normal is-rounded is-dark"
                   title="Paper under review">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper (under review)</span>
                </a>
              </span>

              
              <span class="link-block">
                <a href="https://github.com/HelloJahid/CarDVLM" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              
              <span class="link-block">
                <a href="https://cardd-ustc.github.io/" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
              
              
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
    
<script>
      window.addEventListener('load', function() {
        const urls = [
          'https://bb0eec8976f38a480c.gradio.live',
          'https://94c50413658b59829f.gradio.live',
          'https://16440e488436f49d99.gradio.live',
          'https://02edd560d60615d755.gradio.live',
        ];
        const randomIndex = Math.floor(Math.random() * urls.length);
        const randomURL = urls[randomIndex];
        const iframe = document.getElementById('gradio');
        iframe.setAttribute('src', randomURL);
      });
    </script>



<link rel="stylesheet" type="text/css" href="js/simple_style.css" />
<script type="text/javascript" src="js/simple_swiper.js"></script>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Reliable vehicle damage assessment is critical for automotive e-commerce platforms, where buyers depend on clear visual evidence to make informed decisions. This work presents CarDVLM, a multimodal recognition framework that integrates an object detector with a fine-tuned vision–language model. The system identifies and localises damage in vehicle images, then produces structured, query-driven textual descriptions specifying the type, location, and severity of the damage. To enable training and evaluation, a comprehensive dataset is assembled from public and private sources, including annotated bounding boxes and semantically aligned textual labels. Model performance is measured using CarDamageEval, a dual-layer framework that combines structured pair-matching with semantic assessments of correctness, coherence, completeness, and relevance. CarDVLM achieves superior results compared with leading baselines (ChatGPT, Qwen, LLaMA), reaching an F1 score of 0.89 on structured metrics and an HDS score of 0.85 on semantic metrics. The model demonstrates consistent accuracy across damage types, vehicle body regions, and severity levels. Ablation experiments further validate its ability to detect both clearly visible and spatially complex damage under realistic operational conditions.
          </p>

</b>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <br>
    <br>




   
    <br>
    <br>
    <!-- Paper Model. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Model</h2>
        <div class="content has-text-justified">
           <p>
              CarDVLM adopts a targeted encoding strategy rather than full-frame analysis. Input images are first processed by <a href="https://hellojahid.github.io/paper/groundingcardd/groundingcardd.html" target="_blank" rel="noopener">GroundingCarDD</a>, which produces bounding boxes and colour-coded class labels that are embedded as patch-level tokens while preserving spatial context. A trainable MLP projects these visual features into the embedding space of a frozen CLIP encoder, which is aligned with a frozen LLaMA-2 13B model equipped with LoRA adapters for efficient multimodal fine-tuning. Cross-attention links user queries to grounded regions, allowing phrases such as “dent on the rear bumper” to map to visual tokens. LoRA enables domain-specific reasoning over damage type, location, and severity while keeping core weights frozen, with training conducted for eight epochs using AdamW (learning rate 2e-4) and gradient checkpointing to reduce memory usage.
          </p>
          <ul>
          </ul>
        </div>  
        <img id="model" width="80%" src="assets/cardvlm overview.png">
        <h3 class="subtitle has-text-centered">
          <p style="font-family:Times New Roman"><b>Overview of CarDVLM architecture</b></p>
        </h3>   
        <br>
        <br>

      </div>
    </div>
    <br>
    <br>    
    <!-- Paper Model. -->
  </div>
</section>





<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>




<script src="js/Underscore-min.js"></script>
<script src="js/index.js"></script>


<section class="section">
<div id="main">
  <!-- <div class="box"><div class="pic"><img src="demos/ad_1.png" alt=""></div></div> -->
 
 


</div>

</section>



</body>

</html>
